from __gin__ import dynamic_registration
import __main__ as train_script
from flax import linen
from flaxformer.architectures.dual_encoder import dual_encoder_architecture
from flaxformer.architectures.dual_encoder import l2_norm
from flaxformer.architectures.dual_encoder import poolings
from flaxformer.architectures.dual_encoder import similarity_functions
from flaxformer.architectures.t5 import t5_architecture
from flaxformer.components.attention import dense_attention
from flaxformer.components import dense
from flaxformer.components import embedding
from flaxformer.components import layer_norm
from flaxformer.components import relative_position_biases
import seqio
from t5x import adafactor
from t5x import gin_utils
from t5x import models
from t5x import partitioning
from t5x import train
from t5x import trainer
from t5x import utils
from t5x_retrieval import adafactor_utils
from t5x_retrieval import feature_converters
from t5x_retrieval import models as models2
from t5x_retrieval import partitioning as t5xr_partitioning

# Macros:
# ==============================================================================
ACTIVATION_DTYPE = 'bfloat16'
ACTIVATION_PARTITIONING_DIMS = 1
ARCHITECTURE = @dual_encoder_architecture.DualEncoder()
BATCH_SIZE = 128
BIAS_INIT = @bias_init/linen.initializers.normal()
DROPOUT_FACTORY = @dropout_factory/linen.Dropout
DROPOUT_RATE = 0.1
EMBED_DIM = 768
EVAL_PERIOD = 1000
EVAL_STEPS = 20
EVALUATOR_NUM_EXAMPLES = None
EVALUATOR_USE_MEMORY_CACHE = True
HEAD_DIM = 64
INITIAL_CHECKPOINT_PATH = \
    'gs://t5-data/pretrained_models/t5x/mt5_base/checkpoint_1000000'
JSON_WRITE_N_RESULTS = None
MIXTURE_OR_TASK_MODULE = 't5x_retrieval.tasks'
MIXTURE_OR_TASK_NAME = 'multilingual_marco_mixture'
MLP_DIM = 2048
MODEL = @models2.DualEncoderModel()
MODEL_DIR = 'gs://pongo-bucket/odunayo/mt5x_retrieval/20221220'
NUM_EMBEDDINGS = 250112
NUM_HEADS = 12
NUM_LAYERS = 12
OPTIMIZER = @adafactor.Adafactor()
PROJECTION_DIM = 768
RANDOM_SEED = None
SCALE = 1.0
TASK_FEATURE_LENGTHS = {'inputs': 64, 'targets': 256}
TRAIN_STEPS = 1100000
USE_CACHED_TASKS = False
USE_HARDWARE_RNG = False
VOCABULARY = @seqio.SentencePieceVocabulary()

# Parameters for adafactor.Adafactor:
# ==============================================================================
adafactor.Adafactor.decay_rate = 0.8
adafactor.Adafactor.logical_factor_rules = @adafactor_utils.logical_factor_rules()
adafactor.Adafactor.step_offset = 0

# Parameters for similarity_functions.BatchDotProduct:
# ==============================================================================
similarity_functions.BatchDotProduct.name = 'batch_dot_product'

# Parameters for utils.CheckpointConfig:
# ==============================================================================
utils.CheckpointConfig.restore = @utils.RestoreCheckpointConfig()
utils.CheckpointConfig.save = @utils.SaveCheckpointConfig()

# Parameters for utils.create_learning_rate_scheduler:
# ==============================================================================
utils.create_learning_rate_scheduler.base_learning_rate = 0.001
utils.create_learning_rate_scheduler.decay_factor = 1.25e-06
utils.create_learning_rate_scheduler.factors = 'linear_decay'
utils.create_learning_rate_scheduler.step_offset = 999900
utils.create_learning_rate_scheduler.warmup_steps = 1000

# Parameters for infer_eval/utils.DatasetConfig:
# ==============================================================================
infer_eval/utils.DatasetConfig.batch_size = %BATCH_SIZE
infer_eval/utils.DatasetConfig.mixture_or_task_name = %MIXTURE_OR_TASK_NAME
infer_eval/utils.DatasetConfig.module = %MIXTURE_OR_TASK_MODULE
infer_eval/utils.DatasetConfig.pack = False
infer_eval/utils.DatasetConfig.seed = 42
infer_eval/utils.DatasetConfig.shuffle = False
infer_eval/utils.DatasetConfig.split = 'validation'
infer_eval/utils.DatasetConfig.task_feature_lengths = None
infer_eval/utils.DatasetConfig.use_cached = %USE_CACHED_TASKS

# Parameters for train/utils.DatasetConfig:
# ==============================================================================
train/utils.DatasetConfig.batch_size = 512
train/utils.DatasetConfig.mixture_or_task_name = %MIXTURE_OR_TASK_NAME
train/utils.DatasetConfig.module = %MIXTURE_OR_TASK_MODULE
train/utils.DatasetConfig.pack = False
train/utils.DatasetConfig.seed = None
train/utils.DatasetConfig.shuffle = True
train/utils.DatasetConfig.split = 'train'
train/utils.DatasetConfig.task_feature_lengths = %TASK_FEATURE_LENGTHS
train/utils.DatasetConfig.use_cached = %USE_CACHED_TASKS

# Parameters for train_eval/utils.DatasetConfig:
# ==============================================================================
train_eval/utils.DatasetConfig.batch_size = %BATCH_SIZE
train_eval/utils.DatasetConfig.mixture_or_task_name = %MIXTURE_OR_TASK_NAME
train_eval/utils.DatasetConfig.module = %MIXTURE_OR_TASK_MODULE
train_eval/utils.DatasetConfig.pack = False
train_eval/utils.DatasetConfig.seed = 42
train_eval/utils.DatasetConfig.shuffle = False
train_eval/utils.DatasetConfig.split = 'validation'
train_eval/utils.DatasetConfig.task_feature_lengths = %TASK_FEATURE_LENGTHS
train_eval/utils.DatasetConfig.use_cached = %USE_CACHED_TASKS

# Parameters for projection_layer/dense.DenseGeneral:
# ==============================================================================
projection_layer/dense.DenseGeneral.bias_init = %BIAS_INIT
projection_layer/dense.DenseGeneral.dtype = 'float32'
projection_layer/dense.DenseGeneral.features = %PROJECTION_DIM
projection_layer/dense.DenseGeneral.kernel_axis_names = ('embed', 'affinity')
projection_layer/dense.DenseGeneral.kernel_init = \
    @projection_layer/linen.initializers.variance_scaling()
projection_layer/dense.DenseGeneral.use_bias = False

# Parameters for dropout_factory/linen.Dropout:
# ==============================================================================
dropout_factory/linen.Dropout.broadcast_dims = (-2,)
dropout_factory/linen.Dropout.rate = %DROPOUT_RATE

# Parameters for dual_encoder_architecture.DualEncoder:
# ==============================================================================
dual_encoder_architecture.DualEncoder.dtype = %ACTIVATION_DTYPE
dual_encoder_architecture.DualEncoder.encoder_factory = @t5_architecture.Encoder
dual_encoder_architecture.DualEncoder.l2_norm_factory = @l2_norm.L2Norm
dual_encoder_architecture.DualEncoder.pooler_factory = @poolings.MeanPooling
dual_encoder_architecture.DualEncoder.projection_layer_factory = \
    @projection_layer/dense.DenseGeneral
dual_encoder_architecture.DualEncoder.shared_token_embedder_factory = \
    @embedding.Embed
dual_encoder_architecture.DualEncoder.similarity_layer_factory = \
    @similarity_functions.BatchDotProduct

# Parameters for feature_converters.DualEncoderFeatureConverterFactory:
# ==============================================================================
feature_converters.DualEncoderFeatureConverterFactory.feature_specs = \
    (('inputs', 'int32', 1, 0), ('targets', 'int32', 1, 0))

# Parameters for models2.DualEncoderModel:
# ==============================================================================
models2.DualEncoderModel.feature_converter_cls = \
    @feature_converters.DualEncoderFeatureConverterFactory()
models2.DualEncoderModel.input_vocabulary = %VOCABULARY
models2.DualEncoderModel.module = %ARCHITECTURE
models2.DualEncoderModel.optimizer_def = %OPTIMIZER
models2.DualEncoderModel.output_vocabulary = %VOCABULARY
models2.DualEncoderModel.use_align_uniform = False
models2.DualEncoderModel.use_negatives = False

# Parameters for embedding.Embed:
# ==============================================================================
embedding.Embed.attend_dtype = 'float32'
embedding.Embed.cast_input_dtype = 'int32'
embedding.Embed.dtype = %ACTIVATION_DTYPE
embedding.Embed.embedding_init = @token_embedder_init/linen.initializers.normal()
embedding.Embed.features = %EMBED_DIM
embedding.Embed.name = 'token_embedder'
embedding.Embed.num_embeddings = %NUM_EMBEDDINGS
embedding.Embed.one_hot = True

# Parameters for t5_architecture.Encoder:
# ==============================================================================
t5_architecture.Encoder.dtype = %ACTIVATION_DTYPE
t5_architecture.Encoder.input_dropout_factory = %DROPOUT_FACTORY
t5_architecture.Encoder.layer_factory = @t5_architecture.EncoderLayer
t5_architecture.Encoder.layer_norm_factory = @layer_norm.T5LayerNorm
t5_architecture.Encoder.num_layers = %NUM_LAYERS
t5_architecture.Encoder.output_dropout_factory = %DROPOUT_FACTORY
t5_architecture.Encoder.position_embedder_factory = None
t5_architecture.Encoder.shared_relative_position_bias_factory = \
    @relative_position_biases.RelativePositionBiases

# Parameters for t5_architecture.EncoderLayer:
# ==============================================================================
t5_architecture.EncoderLayer.activation_partitioning_dims = \
    %ACTIVATION_PARTITIONING_DIMS
t5_architecture.EncoderLayer.attention = \
    @dense_attention.MultiHeadDotProductAttention()
t5_architecture.EncoderLayer.dropout_factory = %DROPOUT_FACTORY
t5_architecture.EncoderLayer.layer_norm_factory = @layer_norm.T5LayerNorm
t5_architecture.EncoderLayer.mlp = @dense.MlpBlock()

# Parameters for seqio.Evaluator:
# ==============================================================================
seqio.Evaluator.logger_cls = \
    [@seqio.PyLoggingLogger, @seqio.TensorBoardLogger, @seqio.JSONLogger]
seqio.Evaluator.num_examples = %EVALUATOR_NUM_EXAMPLES
seqio.Evaluator.use_memory_cache = %EVALUATOR_USE_MEMORY_CACHE

# Parameters for seqio.JSONLogger:
# ==============================================================================
seqio.JSONLogger.write_n_results = %JSON_WRITE_N_RESULTS

# Parameters for dense.MlpBlock:
# ==============================================================================
dense.MlpBlock.activations = ('gelu', 'linear')
dense.MlpBlock.bias_init = %BIAS_INIT
dense.MlpBlock.dtype = %ACTIVATION_DTYPE
dense.MlpBlock.final_dropout_rate = 0
dense.MlpBlock.intermediate_dim = %MLP_DIM
dense.MlpBlock.intermediate_dropout_rate = %DROPOUT_RATE
dense.MlpBlock.kernel_init = @mlp_kernel_init/linen.initializers.variance_scaling()
dense.MlpBlock.use_bias = False

# Parameters for dense_attention.MultiHeadDotProductAttention:
# ==============================================================================
dense_attention.MultiHeadDotProductAttention.bias_init = %BIAS_INIT
dense_attention.MultiHeadDotProductAttention.broadcast_dropout = True
dense_attention.MultiHeadDotProductAttention.dropout_rate = %DROPOUT_RATE
dense_attention.MultiHeadDotProductAttention.dtype = %ACTIVATION_DTYPE
dense_attention.MultiHeadDotProductAttention.head_dim = %HEAD_DIM
dense_attention.MultiHeadDotProductAttention.kernel_init = \
    @attention_kernel_init/linen.initializers.variance_scaling()
dense_attention.MultiHeadDotProductAttention.num_heads = %NUM_HEADS
dense_attention.MultiHeadDotProductAttention.use_bias = False

# Parameters for bias_init/linen.initializers.normal:
# ==============================================================================
bias_init/linen.initializers.normal.stddev = 1e-06

# Parameters for token_embedder_init/linen.initializers.normal:
# ==============================================================================
token_embedder_init/linen.initializers.normal.stddev = 1.0

# Parameters for partitioning.PjitPartitioner:
# ==============================================================================
partitioning.PjitPartitioner.logical_axis_rules = \
    @partitioning.standard_logical_axis_rules()
partitioning.PjitPartitioner.model_parallel_submesh = None
partitioning.PjitPartitioner.num_partitions = 1

# Parameters for relative_position_biases.RelativePositionBiases:
# ==============================================================================
relative_position_biases.RelativePositionBiases.dtype = %ACTIVATION_DTYPE
relative_position_biases.RelativePositionBiases.embedding_init = \
    @relative_position_bias_init/linen.initializers.variance_scaling()
relative_position_biases.RelativePositionBiases.max_distance = 128
relative_position_biases.RelativePositionBiases.num_buckets = 32
relative_position_biases.RelativePositionBiases.num_heads = %NUM_HEADS

# Parameters for utils.RestoreCheckpointConfig:
# ==============================================================================
utils.RestoreCheckpointConfig.assignment_map = (('state/param_states.*', None),)
utils.RestoreCheckpointConfig.dtype = 'float32'
utils.RestoreCheckpointConfig.fallback_to_scratch = True
utils.RestoreCheckpointConfig.mode = 'specific'
utils.RestoreCheckpointConfig.path = %INITIAL_CHECKPOINT_PATH

# Parameters for utils.SaveCheckpointConfig:
# ==============================================================================
utils.SaveCheckpointConfig.dtype = 'float32'
utils.SaveCheckpointConfig.keep = 10
utils.SaveCheckpointConfig.period = 500
utils.SaveCheckpointConfig.save_dataset = False

# Parameters for seqio.SentencePieceVocabulary:
# ==============================================================================
seqio.SentencePieceVocabulary.sentencepiece_model_file = \
    'gs://t5-data/vocabs/mc4.250000.100extra/sentencepiece.model'

# Parameters for partitioning.standard_logical_axis_rules:
# ==============================================================================
partitioning.standard_logical_axis_rules.additional_rules = \
    @t5xr_partitioning.standard_logical_axis_rules()

# Parameters for layer_norm.T5LayerNorm:
# ==============================================================================
layer_norm.T5LayerNorm.dtype = %ACTIVATION_DTYPE

# Parameters for train.train:
# ==============================================================================
train.train.checkpoint_cfg = @utils.CheckpointConfig()
train.train.eval_period = 500
train.train.eval_steps = 20
train.train.infer_eval_dataset_cfg = None
train.train.inference_evaluator_cls = @seqio.Evaluator
train.train.model = %MODEL
train.train.model_dir = %MODEL_DIR
train.train.partitioner = @partitioning.PjitPartitioner()
train.train.random_seed = None
train.train.summarize_config_fn = @gin_utils.summarize_gin_config
train.train.total_steps = %TRAIN_STEPS
train.train.train_dataset_cfg = @train/utils.DatasetConfig()
train.train.train_eval_dataset_cfg = @train_eval/utils.DatasetConfig()
train.train.trainer_cls = @trainer.Trainer
train.train.use_hardware_rng = %USE_HARDWARE_RNG

# Parameters for trainer.Trainer:
# ==============================================================================
trainer.Trainer.learning_rate_fn = @utils.create_learning_rate_scheduler()
trainer.Trainer.num_microbatches = None

# Parameters for attention_kernel_init/linen.initializers.variance_scaling:
# ==============================================================================
attention_kernel_init/linen.initializers.variance_scaling.distribution = 'normal'
attention_kernel_init/linen.initializers.variance_scaling.mode = 'fan_in'
attention_kernel_init/linen.initializers.variance_scaling.scale = %SCALE

# Parameters for mlp_kernel_init/linen.initializers.variance_scaling:
# ==============================================================================
mlp_kernel_init/linen.initializers.variance_scaling.distribution = \
    'truncated_normal'
mlp_kernel_init/linen.initializers.variance_scaling.mode = 'fan_in'
mlp_kernel_init/linen.initializers.variance_scaling.scale = %SCALE

# Parameters for projection_layer/linen.initializers.variance_scaling:
# ==============================================================================
projection_layer/linen.initializers.variance_scaling.distribution = \
    'truncated_normal'
projection_layer/linen.initializers.variance_scaling.mode = 'fan_in'
projection_layer/linen.initializers.variance_scaling.scale = %SCALE

# Parameters for relative_position_bias_init/linen.initializers.variance_scaling:
# ==============================================================================
relative_position_bias_init/linen.initializers.variance_scaling.distribution = \
    'uniform'
relative_position_bias_init/linen.initializers.variance_scaling.mode = 'fan_avg'
relative_position_bias_init/linen.initializers.variance_scaling.scale = %SCALE
